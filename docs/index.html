<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <style>
        div.padded 
        {
            padding-top: 0px;
            padding-right: 180px;
            padding-bottom: 0.25in;
            padding-left: 180px;
            line-height:24px;
            font-size: 19px;
        }
        
    div.site-header 
   {
    background: #FFFFFF;
    box-shadow: 0px 4px 4px rgba(0, 0, 0, 0.25);
    overflow: auto; 
   }
 
        div.title-bar {
    float: right;
    padding: 5px;
}
        div.title-bar ul {
    list-style-type: none;
    overflow: hidden;
    margin-block-start: 0em;
    margin-block-end: 0em;
  }

div.title-bar li {
    padding: 5px;
    float: left;
}
        
div.title-bar li a {
    display: block;
    text-align: center;
    text-decoration: none;
    font-family: Source Sans Pro;
    font-style: normal;
    font-weight: 600;
    font-size: 18px;
    line-height: normal;
    color: rgb(129, 129, 129);
    padding: 16px;
}

div.title-bar li a:hover {
    background-color: rgb(246, 246, 246);
    border-radius: 18px;
    color: #5c5c5c;
}
        
 div.row:after {
    content: "";
    display: table;
    clear: both;
}
    </style>
    
    <title>3D reconstruction | CS 184</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" media="screen" />
    
</head>
<body>
  <div class="site-header">
                <div class="title-bar">
                    <ul>
                        <li>
                            <a href="proposal.html">Proposal</a>
                        </li>
                        <li>
                            <a href="index.html">Milestone Report</a>
                        </li>
                        <li>
                            <a href="https://drive.google.com/file/d/1nbhgacKcmNlMxO7RUrd23xWL2heIbyCb/view?usp=sharing">Final Report</a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    
    <h1 align="middle">Milestone Report</h1>
    <h2 align="middle">Jianwei Zhang, Fanwei Kong, Chengjie Zhu
    </h2>

    <div class="padded">

       
       <p><a href="https://drive.google.com/open?id=1FA7YprHgQdqgiFklOKyoRRc4QYRZGbYJ">284A milestone report </a></p>
       <p><a href="https://www.youtube.com/watch?v=_C7L2i4lVw8&feature=youtu.be">Link to video</a>
    </p>
    <p><a href="https://docs.google.com/presentation/d/1P6M8wqodsGqGSn_ObyNx_gn9aIO5UgVuXIzeiMckq8A/edit?usp=sharing">Presentation slides</a></p>

        <h2 align="left">Project Overview</h2>
        
        <p>Our Reconstruction system comprises the visual odometry part and mesh reconstruction part.</p>
 <p>The Visual Odometry System is divided into Frontend and Backend. The Visual Frontend is responsible for detecting and tracking feature points while localizing the camera pose in real time. We used GFTTDetector in OpenCV to detect feature points and used optical flow for tracking. When the tracked feature points are below a threshold, a new keyframe will be inserted, new features will be detected and backend optimization will be triggered.  Backend optimization uses Bundle Adjustment to optimize camera poses of several keyframes and associated feature points jointly. We employed the Levenberg–Marquardt optimization algorithm implemented in g2o. 
</p>
<p>The visual odometry part outputs point cloud in the world coordinates for each frame. We then applied surface reconstruction techniques to generate mesh from the point cloud. Point Cloud Library (PCL) was used to process the point clouds. Namely, at each frame as more points being integrated into the fused point cloud, a VoxelGrid filter was applied to downsample the amount of points by constructing a voxel grid over the point cloud and represents the points sharing the same voxel with the voxel centroid. A Statistical Outlier Removal filter was applied to reduce noise. We have applied the Poisson surface reconstruction algorithm as well as the Marching cube algorithm to generate surface meshes, using PCL’s implementations. 
</p>
        <h2 align="left">Our progress and preliminary results</h2>
        
        <p>We have completed the Visual Odometry and point cloud reconstruction as shown below. The top right image is an illustration of the detected feature points. The bottom right image is an illustration of Bundle Adjustment. Camera poses and associated feature points are shown in the image. The left image is a preliminary point cloud reconstruction result.
        </p>
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/1.png" align="middle" width="600px" />
                        <figcaption align="center">Visual Odometry System Demo</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <p>For mesh reconstruction, we first compared the following different surface processing techniques on the Stanford bunny: Poisson surface reconstruction, marching cube with signed distance functions estimated by Hoppe et al., or by radial basis function. All methods utilized KDTree as the acceleration structures.The figure below displays the reconstructed meshes using different methods. The top row shows the point cloud and meshes for a full bunny while the bottom row shows those for half of the bunny. The Poisson surface reconstruction produced mesh with the best quality compared with the marching cube methods. This could be due to a normal estimation issue of PCL. Since point normals are estimated to generate the signed distance function for use in the marching cube algorithm, a noisy normal estimate that generates inconsistent point normals will lead to broken meshes. </p>
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/2.png" align="middle" width="600px" />
                        <figcaption align="center">Different surface processing techniques</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <p>We therefore proceeded to use Poisson surface reconstruction to mesh our point cloud. The figure below displays the point cloud and the reconstructed meshes at different viewing angles. The color coding is based on the object colors. The reconstruction was able to represent the major objects present in the scene. However, the mesh has quite a lot of noise, especially in the back of the room where the depth estimation is noisy.  
        </p>
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/3.png" align="middle" width="600px" />
                        <figcaption align="center">Poisson surface reconstruction</figcaption>
                    </td>
                </tr>
            </table>
        </div>
       

        <h2 align="left">Reflect on progress </h2>
        <p>Generally we are progressing as planned. We have successfully set up the framework to estimate camera position, generate point clouds and reconstruct mesh. The plan for the next week is still to implement the marching cube reconstruction with truncated signed distance function (TSDF). Since TSDF represents the surface implicitly by a gradient field, rather than point based normals required by Poisson or Hoppe, it may help to reduce the noise in the reconstructed surface. We found an implementation of TSDF with the voxel hashing acceleration structure and plan to modify and integrate it into our framework. 
        </p>
        <h2 align="left">Work plan update</h2>
       <p>We are on schedule, so there is nothing new to update.</p>
       
